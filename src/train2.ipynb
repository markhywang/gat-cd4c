{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy of train.ipynb (run on GPU 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Local imports\n",
    "from train import train_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:1\n"
     ]
    }
   ],
   "source": [
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:1\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    \"use_small_dataset\": False,\n",
    "    \"batch_size\": 64,\n",
    "    \"stoppage_epochs\": 64,\n",
    "    \"max_epochs\": 512,\n",
    "    \"seed\": 42,\n",
    "    \"data_path\": \"../data\",\n",
    "    \"frac_train\": 0.8,\n",
    "    \"frac_validation\": 0.1,\n",
    "    \"frac_test\": 0.1,\n",
    "    \"huber_beta\": 0.5,\n",
    "    \"weight_decay\": 1e-3,\n",
    "    \"lr\": 3e-4,\n",
    "    \"scheduler_patience\": 10,\n",
    "    \"scheduler_factor\": 0.5,\n",
    "    \"hidden_size\": 96,\n",
    "    \"num_layers\": 7,\n",
    "    \"num_attn_heads\": 6,\n",
    "    \"dropout\": 0.2,\n",
    "    \"pooling_dropout\": 0.1,\n",
    "    \"pooling_dim\": 96,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model parameters: 181635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/512: 100%|██████████████████████████████████████████████████████████████████████| 906/906 [02:23<00:00,  6.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/512: \n",
      "Train Loss = 0.75984, Train MSE = 1.46063, Train MAE = 0.98476, Train Acc = 0.56884\n",
      "Val Loss = 0.72340, Val MSE = 1.33789, Val MAE = 0.94704, Val Acc = 0.58305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/512: 100%|██████████████████████████████████████████████████████████████████████| 906/906 [00:40<00:00, 22.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/512: \n",
      "Train Loss = 0.71390, Train MSE = 1.33083, Train MAE = 0.93723, Train Acc = 0.59639\n",
      "Val Loss = 0.69230, Val MSE = 1.25548, Val MAE = 0.91461, Val Acc = 0.60141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/512: 100%|██████████████████████████████████████████████████████████████████████| 906/906 [00:41<00:00, 21.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/512: \n",
      "Train Loss = 0.69720, Train MSE = 1.28785, Train MAE = 0.91937, Train Acc = 0.60503\n",
      "Val Loss = 0.68277, Val MSE = 1.23370, Val MAE = 0.90486, Val Acc = 0.60251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/512: 100%|██████████████████████████████████████████████████████████████████████| 906/906 [00:41<00:00, 21.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/512: \n",
      "Train Loss = 0.68689, Train MSE = 1.26051, Train MAE = 0.90861, Train Acc = 0.61266\n",
      "Val Loss = 0.67208, Val MSE = 1.20311, Val MAE = 0.89409, Val Acc = 0.60748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/512: 100%|██████████████████████████████████████████████████████████████████████| 906/906 [00:41<00:00, 22.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/512: \n",
      "Train Loss = 0.67973, Train MSE = 1.24262, Train MAE = 0.90113, Train Acc = 0.61708\n",
      "Val Loss = 0.66379, Val MSE = 1.18895, Val MAE = 0.88603, Val Acc = 0.61590\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/512: 100%|██████████████████████████████████████████████████████████████████████| 906/906 [00:40<00:00, 22.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/512: \n",
      "Train Loss = 0.67004, Train MSE = 1.21883, Train MAE = 0.89068, Train Acc = 0.62317\n",
      "Val Loss = 0.65843, Val MSE = 1.17041, Val MAE = 0.88033, Val Acc = 0.62198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/512: 100%|██████████████████████████████████████████████████████████████████████| 906/906 [00:41<00:00, 22.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/512: \n",
      "Train Loss = 0.66558, Train MSE = 1.20639, Train MAE = 0.88657, Train Acc = 0.62683\n",
      "Val Loss = 0.64993, Val MSE = 1.15929, Val MAE = 0.87123, Val Acc = 0.63109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/512: 100%|██████████████████████████████████████████████████████████████████████| 906/906 [00:40<00:00, 22.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/512: \n",
      "Train Loss = 0.66036, Train MSE = 1.19548, Train MAE = 0.88078, Train Acc = 0.62881\n",
      "Val Loss = 0.64892, Val MSE = 1.15204, Val MAE = 0.86890, Val Acc = 0.63082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/512: 100%|██████████████████████████████████████████████████████████████████████| 906/906 [00:40<00:00, 22.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/512: \n",
      "Train Loss = 0.65495, Train MSE = 1.18510, Train MAE = 0.87486, Train Acc = 0.63206\n",
      "Val Loss = 0.63926, Val MSE = 1.13374, Val MAE = 0.85907, Val Acc = 0.63772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/512: 100%|█████████████████████████████████████████████████████████████████████| 906/906 [00:40<00:00, 22.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/512: \n",
      "Train Loss = 0.65216, Train MSE = 1.17721, Train MAE = 0.87200, Train Acc = 0.63401\n",
      "Val Loss = 0.63364, Val MSE = 1.12650, Val MAE = 0.85325, Val Acc = 0.64269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/512: 100%|█████████████████████████████████████████████████████████████████████| 906/906 [00:40<00:00, 22.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/512: \n",
      "Train Loss = 0.64829, Train MSE = 1.16872, Train MAE = 0.86804, Train Acc = 0.63763\n",
      "Val Loss = 0.62785, Val MSE = 1.11044, Val MAE = 0.84774, Val Acc = 0.64669\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/512: 100%|█████████████████████████████████████████████████████████████████████| 906/906 [00:40<00:00, 22.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/512: \n",
      "Train Loss = 0.64210, Train MSE = 1.15477, Train MAE = 0.86129, Train Acc = 0.64224\n",
      "Val Loss = 0.62929, Val MSE = 1.11914, Val MAE = 0.84906, Val Acc = 0.65139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/512: 100%|█████████████████████████████████████████████████████████████████████| 906/906 [00:40<00:00, 22.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/512: \n",
      "Train Loss = 0.64021, Train MSE = 1.15297, Train MAE = 0.85949, Train Acc = 0.64369\n",
      "Val Loss = 0.62023, Val MSE = 1.09187, Val MAE = 0.83854, Val Acc = 0.65525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/512: 100%|█████████████████████████████████████████████████████████████████████| 906/906 [00:40<00:00, 22.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/512: \n",
      "Train Loss = 0.63479, Train MSE = 1.14003, Train MAE = 0.85356, Train Acc = 0.64692\n",
      "Val Loss = 0.61342, Val MSE = 1.07926, Val MAE = 0.83161, Val Acc = 0.65995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/512: 100%|█████████████████████████████████████████████████████████████████████| 906/906 [00:40<00:00, 22.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/512: \n",
      "Train Loss = 0.63252, Train MSE = 1.13688, Train MAE = 0.85095, Train Acc = 0.64928\n",
      "Val Loss = 0.61178, Val MSE = 1.07277, Val MAE = 0.83051, Val Acc = 0.65677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/512: 100%|█████████████████████████████████████████████████████████████████████| 906/906 [00:40<00:00, 22.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/512: \n",
      "Train Loss = 0.62841, Train MSE = 1.12792, Train MAE = 0.84651, Train Acc = 0.65175\n",
      "Val Loss = 0.61566, Val MSE = 1.08441, Val MAE = 0.83429, Val Acc = 0.65774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/512: 100%|█████████████████████████████████████████████████████████████████████| 906/906 [00:40<00:00, 22.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/512: \n",
      "Train Loss = 0.62288, Train MSE = 1.11421, Train MAE = 0.84105, Train Acc = 0.65565\n",
      "Val Loss = 0.60002, Val MSE = 1.05447, Val MAE = 0.81677, Val Acc = 0.66437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/512: 100%|█████████████████████████████████████████████████████████████████████| 906/906 [00:40<00:00, 22.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/512: \n",
      "Train Loss = 0.62220, Train MSE = 1.11261, Train MAE = 0.83992, Train Acc = 0.65577\n",
      "Val Loss = 0.60205, Val MSE = 1.05434, Val MAE = 0.81931, Val Acc = 0.66519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/512: 100%|█████████████████████████████████████████████████████████████████████| 906/906 [00:40<00:00, 22.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/512: \n",
      "Train Loss = 0.61956, Train MSE = 1.10570, Train MAE = 0.83750, Train Acc = 0.65722\n",
      "Val Loss = 0.59286, Val MSE = 1.02943, Val MAE = 0.80976, Val Acc = 0.67030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/512: 100%|█████████████████████████████████████████████████████████████████████| 906/906 [00:40<00:00, 22.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/512: \n",
      "Train Loss = 0.61383, Train MSE = 1.09245, Train MAE = 0.83129, Train Acc = 0.66135\n",
      "Val Loss = 0.59805, Val MSE = 1.04511, Val MAE = 0.81479, Val Acc = 0.66920\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/512: 100%|█████████████████████████████████████████████████████████████████████| 906/906 [00:40<00:00, 22.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/512: \n",
      "Train Loss = 0.61157, Train MSE = 1.08908, Train MAE = 0.82888, Train Acc = 0.66492\n",
      "Val Loss = 0.59228, Val MSE = 1.03286, Val MAE = 0.80797, Val Acc = 0.67472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/512: 100%|█████████████████████████████████████████████████████████████████████| 906/906 [00:40<00:00, 22.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/512: \n",
      "Train Loss = 0.61041, Train MSE = 1.08544, Train MAE = 0.82754, Train Acc = 0.66475\n",
      "Val Loss = 0.58741, Val MSE = 1.02208, Val MAE = 0.80307, Val Acc = 0.67237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/512: 100%|█████████████████████████████████████████████████████████████████████| 906/906 [00:40<00:00, 22.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/512: \n",
      "Train Loss = 0.60594, Train MSE = 1.07393, Train MAE = 0.82264, Train Acc = 0.66718\n",
      "Val Loss = 0.59008, Val MSE = 1.03252, Val MAE = 0.80563, Val Acc = 0.67375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/512:  91%|██████████████████████████████████████████████████████████████▌      | 821/906 [00:37<00:03, 22.15it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01margparse\u001b[39;00m\n\u001b[1;32m      3\u001b[0m training_args \u001b[38;5;241m=\u001b[39m argparse\u001b[38;5;241m.\u001b[39mNamespace(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39margs)\n\u001b[0;32m----> 4\u001b[0m train_model(training_args, device)\n",
      "File \u001b[0;32m~/gat-cd4c/src/train.py:75\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(args, m_device)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(args\u001b[38;5;241m.\u001b[39mmax_epochs):\n\u001b[1;32m     74\u001b[0m     progress_bar \u001b[38;5;241m=\u001b[39m tqdm(train_loader, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00margs\u001b[38;5;241m.\u001b[39mmax_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, leave\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 75\u001b[0m     avg_train_metrics \u001b[38;5;241m=\u001b[39m run_training_epoch(progress_bar, optimizer, model, loss_func)\n\u001b[1;32m     76\u001b[0m     avg_val_metrics \u001b[38;5;241m=\u001b[39m get_validation_metrics(validation_loader, model, loss_func)\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;66;03m# Unpack all metrics\u001b[39;00m\n",
      "File \u001b[0;32m~/gat-cd4c/src/train.py:130\u001b[0m, in \u001b[0;36mrun_training_epoch\u001b[0;34m(progress_bar, optimizer, model, loss_func)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_data \u001b[38;5;129;01min\u001b[39;00m progress_bar:\n\u001b[1;32m    126\u001b[0m     node_features, edge_features, adjacency_matrix, pchembl_score \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    127\u001b[0m         x\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39mfloat32)\u001b[38;5;241m.\u001b[39mto(device) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m batch_data\n\u001b[1;32m    128\u001b[0m     ]\n\u001b[0;32m--> 130\u001b[0m     preds \u001b[38;5;241m=\u001b[39m model(node_features, edge_features, adjacency_matrix)\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    131\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss_func(preds, pchembl_score)\n\u001b[1;32m    133\u001b[0m     cum_training_samples \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m preds\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m/scratch/local3/2024/aguo/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/scratch/local3/2024/aguo/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/gat-cd4c/src/model.py:34\u001b[0m, in \u001b[0;36mGraphAttentionNetwork.forward\u001b[0;34m(self, node_features, edge_features, adjacency_matrix)\u001b[0m\n\u001b[1;32m     31\u001b[0m input_tuple \u001b[38;5;241m=\u001b[39m (node_features, edge_features, adjacency_matrix)\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# [B, N, F_in] -> [B, N, F_out]\u001b[39;00m\n\u001b[0;32m---> 34\u001b[0m updated_node_features, _, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgat_layers(input_tuple)\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m# Perform global attention pooling for final learning process\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m# [B, N, F_out] -> [B, 1]\u001b[39;00m\n\u001b[1;32m     38\u001b[0m pchembl_scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mglobal_attn_pooling(updated_node_features)\n",
      "File \u001b[0;32m/scratch/local3/2024/aguo/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/scratch/local3/2024/aguo/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/scratch/local3/2024/aguo/miniconda3/lib/python3.12/site-packages/torch/nn/modules/container.py:250\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 250\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m module(\u001b[38;5;28minput\u001b[39m)\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m/scratch/local3/2024/aguo/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/scratch/local3/2024/aguo/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/gat-cd4c/src/model.py:133\u001b[0m, in \u001b[0;36mGraphAttentionLayer.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    130\u001b[0m edge_residual \u001b[38;5;241m=\u001b[39m edge_features\n\u001b[1;32m    132\u001b[0m \u001b[38;5;66;03m# [B, N, F_in] -> [B, N, F_out]\u001b[39;00m\n\u001b[0;32m--> 133\u001b[0m new_node_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnode_projection(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer_norm_1(node_features))\n\u001b[1;32m    135\u001b[0m \u001b[38;5;66;03m# [B, N, N, F_edge] -> [B, N, N, F_edge]\u001b[39;00m\n\u001b[1;32m    136\u001b[0m edge_normalized \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer_norm_2(edge_features)\n",
      "File \u001b[0;32m/scratch/local3/2024/aguo/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/scratch/local3/2024/aguo/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/scratch/local3/2024/aguo/miniconda3/lib/python3.12/site-packages/torch/nn/modules/linear.py:125\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mlinear(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "\n",
    "training_args = argparse.Namespace(**args)\n",
    "train_model(training_args, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
